{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.libraries import *\n",
    "from utils.objects import *\n",
    "from utils.functions import *\n",
    "from definitions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=20\n",
    "period=\"W\"\n",
    "root_path=ROOT_PATH\n",
    "target=\"SP500\"\n",
    "cutoff_date=\"2023-07-07\"\n",
    "cross_val=5\n",
    "data_path=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collecting & Preparing the data\n",
    "### Setting up the configuration\n",
    "# Se utiliza un rango de 20 aÃ±os para la extraccion de datos econÃ³micos\n",
    "timeframe = 365*years\n",
    "today = datetime.today()\n",
    "end = today.strftime(\"%Y-%m-%d\")\n",
    "start = (today - dt.timedelta(days=timeframe)).strftime(\"%Y-%m-%d\")\n",
    "periods = period\n",
    "\n",
    "medidas = [\"mean\", \"median\", \"mode\", \"Min\", \"Percentil_25\", \"Percentil_75\",\"Max\", \"var\", \"std\", \"skew\", \"kurt\"]\n",
    "\n",
    "ROOT_PATH = Path(root_path)\n",
    "config_paths = [\n",
    "    \"config\\Market_Data_Config.csv\",\n",
    "    \"config\\Economic_Data_Config.csv\",\n",
    "    \"config\\Calc_Data_Config.csv\"\n",
    "]\n",
    "market_config = ROOT_PATH.joinpath(config_paths[0])\n",
    "economic_config = ROOT_PATH.joinpath(config_paths[1]).abspath()\n",
    "calc_config = ROOT_PATH.joinpath(config_paths[2]).abspath()\n",
    "\n",
    "target_list = pd.read_csv(market_config, sep=\";\", header=0).loc[:, \"Codigo\"].to_list()\n",
    "\n",
    "markets_used = pd.read_csv(market_config, sep=\";\", header=0).loc[:, \"Codigo\"].to_list()\n",
    "\n",
    "markets_remove = pd.read_csv(market_config, sep=\";\", header=0).loc[:, \"Market\"].to_list()\n",
    "# markets_used = ['SPY', 'GDX', 'BND']\n",
    "\n",
    "target = target\n",
    "\n",
    "# ML random seed\n",
    "seed = 2\n",
    "\n",
    "extract = True\n",
    "\n",
    "cutoff_date = cutoff_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Load the market data config\n",
      "> Load the economic data config\n",
      "> Setting up the indicator dictionaries\n",
      "> Extracting the indicator data\n",
      "   -->Extracting 10-Year Treasury Yield...\n",
      "   -->Extracting 2-Year Treasury Yield...\n",
      "   -->Extracting Federal Funds Effective Rate...\n",
      "   -->Extracting 1-Month Treasury Yield...\n",
      "   -->Extracting 3-Month Treasury Yield...\n",
      "   -->Extracting 5-Year Treasury Yield...\n",
      "   -->Extracting 20-Year Treasury Yield...\n",
      "   -->Extracting 30-Year Treasury Yield...\n",
      "   -->Extracting 15-Year Mortgage Rate...\n",
      "   -->Extracting 30-Year Mortgage Rate...\n",
      "   -->Extracting Unemployment Rate...\n",
      "   -->Extracting GDP...\n",
      "   -->Extracting Real GDP...\n",
      "   -->Extracting CPI...\n",
      "   -->Extracting PPI...\n",
      "   -->Extracting Consumer Confidence Index...\n",
      "   -->Extracting Government Debt...\n",
      "   -->Extracting Debt Service vs Disposable Income...\n",
      "   -->Extracting US Dollar Index...\n",
      "   -->Extracting Corporate Profits...\n",
      "   -->Extracting EBIT...\n",
      "   -->Extracting Retained Earnings...\n",
      "   -->Extracting Building Permits...\n",
      "   -->Extracting Velocity of Money...\n",
      "   -->Extracting Retail Sales...\n",
      "   -->Extracting Industrial Production...\n",
      "Indicators Extracted: Index(['10-Year Treasury Yield', '2-Year Treasury Yield',\n",
      "       'Federal Funds Effective Rate', '1-Month Treasury Yield',\n",
      "       '3-Month Treasury Yield', '5-Year Treasury Yield',\n",
      "       '20-Year Treasury Yield', '30-Year Treasury Yield',\n",
      "       '15-Year Mortgage Rate', '30-Year Mortgage Rate', 'Unemployment Rate',\n",
      "       'GDP', 'Real GDP', 'CPI', 'PPI', 'Consumer Confidence Index',\n",
      "       'Government Debt', 'Government Debt to GDP',\n",
      "       'Debt Service vs Disposable Income', 'US Dollar Index',\n",
      "       'Corporate Profits', 'EBIT', 'Retained Earnings', 'Building Permits',\n",
      "       'Velocity of Money', 'Retail Sales', 'Industrial Production', '3m5y',\n",
      "       '3m10y', '2y10y', '2y20y', '5y10y', '10y30y', '10yTrea30yFRM'],\n",
      "      dtype='object')\n",
      "> Extracting the market data\n",
      "[*********************100%***********************]  15 of 15 completed\n"
     ]
    }
   ],
   "source": [
    "### Loading and extracting the data\n",
    "# Initialize the Economic Data Analyzer class\n",
    "eda = EconomicDataAnalyzer()\n",
    "# Load the Market Data\n",
    "print(\"> Load the market data config\")\n",
    "market = eda.read_config(market_config)\n",
    "market_dict = eda.convert_to_dictionary(markets_used=markets_used)\n",
    "market_dict = market_dict['Market']\n",
    "# Load the economic data config\n",
    "print(\"> Load the economic data config\")\n",
    "econ = eda.read_config(economic_config)\n",
    "fred_series_dict = eda.convert_to_dictionary(markets_used=None)\n",
    "fred_series_dict = fred_series_dict[\"Indicador\"]\n",
    "calc = eda.read_config(calc_config)\n",
    "series_calc_dict = eda.convert_to_dictionary(markets_used=None)\n",
    "series_calc_dict = series_calc_dict[\"Indicador\"]\n",
    "# Setting up the indicator dictionaries\n",
    "print(\"> Setting up the indicator dictionaries\")\n",
    "indicators = {}\n",
    "for ind in list(econ[\"Tipo\"].unique()):\n",
    "    indicators[ind] = econ[econ[\"Tipo\"] == ind][\"Indicador\"].to_list()\n",
    "if extract == True:\n",
    "    # Extracting the indicator data\n",
    "    print(\"> Extracting the indicator data\")\n",
    "    indicators_df = eda.indicator_extraction(fred_series_dict, series_calc_dict, root_path=ROOT_PATH)\n",
    "    # Extracting the market data\n",
    "    print(\"> Extracting the market data\")\n",
    "    stocks = list(market_dict.keys())\n",
    "    market_df = eda.market_extraction(stocks, start, end, root_path=ROOT_PATH)\n",
    "else:\n",
    "    print(\"No data extraction, reading data from data file\")\n",
    "    path = ROOT_PATH.joinpath('data', 'raw', 'indicators_df.csv')\n",
    "    indicators_df = pd.read_csv(path)\n",
    "    path = ROOT_PATH.joinpath('data', 'raw', 'market_df.csv')\n",
    "    market_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Extracting European economic data\n",
    "# import eurostat\n",
    "# #### EU Yield Curve\n",
    "# yield_curve = eurostat.get_data_df(\"irt_euryld_d\")\n",
    "# yld_crv = yield_curve.loc[(~yield_curve[\"bonds\"].str.contains(\"AAA\")) & (yield_curve[\"yld_curv\"].str.contains(\"INS_FWD\")) & (~yield_curve[\"maturity\"].str.contains(\"M\")),:]\n",
    "# yld_crv.set_index(\"maturity\", inplace=True)\n",
    "# yld_crv[\"maturity_int\"] = yld_crv.index.str.split(\"Y\").str[1].astype(int)\n",
    "# yld_crv.sort_values(\"maturity_int\",ascending=True, inplace=True)\n",
    "# yld_crv.drop([\"maturity_int\"], axis=1, inplace=True)\n",
    "# yld_crv = yld_crv.T\n",
    "# yld_crv = yld_crv.loc[yld_crv.index.drop([\"freq\",'yld_curv', 'bonds', 'geo\\TIME_PERIOD'])]\n",
    "# yld_crv.index = pd.to_datetime(yld_crv.index)\n",
    "# yld_lst = []\n",
    "# for yld in yld_crv.columns:\n",
    "#     yld_lst.append(f\"EU_yield_{yld}\")\n",
    "# yld_crv.set_axis(yld_lst, axis=1, inplace=True)\n",
    "# intr_inds = pd.merge(indicators_df, yld_crv, left_index=True, right_index=True)\n",
    "# #### EU HICP\n",
    "# hicp = eurostat.get_data_df(\"PRC_HICP_MIDX\")\n",
    "# hicp = hicp.loc[(hicp[\"geo\\TIME_PERIOD\"] == \"EU\") & (hicp[\"coicop\"] == \"CP00\") & (hicp[\"unit\"] == \"I15\"),:].T\n",
    "# hicp.drop([\"freq\", \"geo\\TIME_PERIOD\", \"coicop\", \"unit\"], axis=0, inplace=True)\n",
    "# hicp.set_axis([\"EU CPI\"], axis=1, inplace=True)\n",
    "# hicp.index = pd.to_datetime(hicp.index)\n",
    "# intr_inds = pd.merge(intr_inds, hicp, left_index=True, right_index=True)\n",
    "# #### EU Government Deficit\n",
    "# gov_def = eurostat.get_data_df(\"GOV_10DD_EDPT1\")\n",
    "# gov_def = gov_def.loc[(gov_def[\"geo\\TIME_PERIOD\"] == \"EA20\") & (gov_def[\"sector\"] == \"S13\") & (gov_def[\"na_item\"] == \"B9\") & (gov_def[\"unit\"] == \"PC_GDP\"), :].T\n",
    "# gov_def.set_axis(gov_def.loc[\"geo\\TIME_PERIOD\"].values, axis=1, inplace=True)\n",
    "# gov_def.drop([\"freq\", \"geo\\TIME_PERIOD\", \"sector\", \"na_item\", \"unit\"], axis=0, inplace=True)\n",
    "# gov_def.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Cleaning the indicator data\n",
      "> Cleaning market data\n"
     ]
    }
   ],
   "source": [
    "## Preparing the data\n",
    "### Data cleaning\n",
    "# Cleaning the indicator data\n",
    "print(\"> Cleaning the indicator data\")\n",
    "df_indicators, df_indicators_cum, df_indicators_diff, df_indicators_rets, df_indicators_limpio = eda.limpiar_indicators(\n",
    "    df_indicators=indicators_df, \n",
    "    indicator_dict=indicators, \n",
    "    resample=periods, \n",
    "    fill_method=\"ffill\", \n",
    "    start=start, \n",
    "    end=end, \n",
    "    root_path=ROOT_PATH)\n",
    "# Cleaning the market data\n",
    "print(\"> Cleaning market data\")\n",
    "df_market, df_markets_rets, df_markets_cum, df_markets_diff  = eda.limpiar_markets(\n",
    "    markets_dict=market_dict,\n",
    "    df_markets=market_df,\n",
    "    resample=periods, \n",
    "    fill_method=\"ffill\", \n",
    "    start=start, \n",
    "    end=end, \n",
    "    root_path=ROOT_PATH)\n",
    "### Merge indicator and market data\n",
    "list_market_dfs = [df_market,df_markets_rets,df_markets_cum,df_markets_diff]\n",
    "list_indicators_dfs = [df_indicators_limpio,df_indicators_rets,df_indicators_cum,df_indicators_diff]\n",
    "\n",
    "df_all_data, df_all_data_rets, df_all_data_cum, df_all_data_diff = eda.merge_data(list_market_dfs, list_indicators_dfs, root_path=ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Engineering\n",
    "### Remove Outliers \n",
    "df = eda.remove_outliers(df_all_data_rets)\n",
    "### Adding features\n",
    "df_all_data[\"CAPE Ratio\"] = df_all_data[\"SP500\"]/(df_all_data[\"Corporate Profits\"]*0.01)\n",
    "df[\"CAPE Ratio\"] = df_all_data[\"SP500\"]/(df_all_data[\"Corporate Profits\"]*0.01)\n",
    "\n",
    "# df_all_data[\"CAPE Ratio\"].plot()\n",
    "def trend_line(df, name, deg=2):\n",
    "    coef = np.polyfit(range(0,len(df[name])), df[name], deg)\n",
    "    x_trend = np.linspace(0,len(df[name]),len(df[name]))\n",
    "    y_trend = np.polyval(coef, x_trend)\n",
    "    df = pd.DataFrame(y_trend, index=df.index, columns=[name])\n",
    "    return df\n",
    "\n",
    "# df_all_data = pd.DataFrame()\n",
    "df_all_data[\"SP_GDP\"] = df_all_data[\"SP500\"]/(df_all_data[\"GDP\"]*.01)\n",
    "df_all_data[\"SP_GDP_trend\"] = trend_line(df_all_data, \"SP_GDP\", deg=5)\n",
    "df[\"SP_GDP\"] = df_all_data[\"SP500\"]/(df_all_data[\"GDP\"]*.01)\n",
    "df[\"SP_GDP_trend\"] = trend_line(df_all_data, \"SP_GDP\", deg=5)\n",
    "\n",
    "# df_all_data = pd.DataFrame()\n",
    "std = df_all_data[\"SP_GDP\"].std()\n",
    "df_all_data[\"SP_GDP_1std\"] = df_all_data[\"SP_GDP_trend\"] + (std)\n",
    "df[\"SP_GDP_1std\"] = df_all_data[\"SP_GDP_trend\"] + (std)\n",
    "\n",
    "# df_all_data = df_all_data.copy()\n",
    "# df_ts = df_all_data.loc[:,df_all_data.columns.str.contains(f\"t-\")]\n",
    "# df_all_data.drop(df_ts.columns,axis=1,inplace=True)\n",
    "for ma in df_all_data.columns:\n",
    "    df_all_data[f\"{ma}_MA\"] = df_all_data[[ma]].rolling(window=52).mean().fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    df_all_data[f\"{ma}_std\"] = df_all_data[[ma]].rolling(window=52).std().fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    df_all_data[f\"{ma}_trend\"] = trend_line(df_all_data[[ma]], ma, deg=6)\n",
    "    df_all_data[f\"{ma}_MA_trend_dif\"] = df_all_data[f\"{ma}_trend\"] - df_all_data[f\"{ma}_MA\"]\n",
    "    \n",
    "    df[f\"{ma}_MA\"] = df_all_data[[ma]].rolling(window=52).mean().fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    df[f\"{ma}_trend\"] = trend_line(df_all_data[[ma]], ma, deg=6)\n",
    "    df[f\"{ma}_MA_trend_dif\"] = df_all_data[f\"{ma}_trend\"] - df_all_data[f\"{ma}_MA\"]\n",
    "### Creating lags in the data\n",
    "list_data_dfs = [df_all_data,df_all_data_rets,df_all_data_cum,df_all_data_diff]\n",
    "\n",
    "df_all_lag_data, df_all_lag_data_rets, df_all_lag_data_cum, df_all_lag_data_diff = eda.lag_data(list_data_dfs, target, n_lags=24)\n",
    "df = eda.remove_outliers(df_all_lag_data_rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mkt in markets_remove:\n",
    "    if mkt == target:\n",
    "        pass\n",
    "    else:\n",
    "        for df_col in df.columns:\n",
    "            if mkt in df_col:\n",
    "                try:\n",
    "                    df.drop(df_col, axis=1, inplace=True)\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RandomForest\n",
      "Processing GradientBoosting\n",
      "Processing SVR\n",
      "Processing KNeighborsRegressor\n",
      "Processing XGBRegressor\n",
      "--> We choose ['RandomForest' 'GradientBoosting' 'XGBRegressor'] as the best models due to their high scores and rmse\n",
      "> Performing feature importance analysis\n",
      "We choose to remove 507 features\n"
     ]
    }
   ],
   "source": [
    "## Data Preprocessing\n",
    "econ_ml = Preprocessor()\n",
    "### Feature Reduction\n",
    "#### Feature selection by correlation\n",
    "df_feat_corr = pd.DataFrame(df.corr().loc[target,:].sort_values(ascending=False))\n",
    "df_feat_relevant_corr = df_feat_corr[(df_feat_corr[target]>0.05) | (df_feat_corr[target]<-0.05)]\n",
    "df_feat_relevant_corr\n",
    "#### Indentifying the most important features\n",
    "##### Splitting the data\n",
    "\n",
    "##### Creating the baseline for feature importance\n",
    "baseline_models = econ_ml.define_baseline_models()\n",
    "\n",
    "X_train, X_test, y_train, y_test = econ_ml.train_test_split_data(data=df, target_col=target, test_size=0.15)\n",
    "model_results, baseline_preds, best_model, best_model_name = econ_ml.baseline_ml(target, X_train, X_test, y_train, y_test, baseline_models)\n",
    "\n",
    "print(\"> Performing feature importance analysis\")\n",
    "df_top_data, feature_importance, top_feature_importance, score = econ_ml.feature_importance(target=target, \n",
    "                                                                                                df_data=df.loc[:cutoff_date],\n",
    "                                                                                                model=best_model,\n",
    "                                                                                                accepted_importance=0.85)\n",
    "#### Feature removal\n",
    "def feature_removal(df, df_top_data, model_results, best_model_name, score):\n",
    "    best_model_score = model_results.loc[best_model_name,\"score\"]\n",
    "    if score > best_model_score*.9:\n",
    "        print(\"We choose to remove \"+str(len(df.columns)-len(df_top_data.columns))+\" features\")\n",
    "        df = df_top_data.copy()\n",
    "    else:\n",
    "        print(\"We choose to keep the original df with \"+str(len(df_top_data.columns))+\" features\")\n",
    "    return df\n",
    "\n",
    "df = feature_removal(df, df_top_data, model_results, best_model_name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the stats\n",
    "\n",
    "mean = df.mean()\n",
    "var = df.var()\n",
    "drift = mean - (.5 * var)\n",
    "std = df.std()\n",
    "\n",
    "# Setting the Monte Carlo Varuables\n",
    "ind = 0\n",
    "T = 104\n",
    "num_ports = 100\n",
    "date_range = pd.date_range(start=cutoff_date, periods=T, freq=\"W\")\n",
    "\n",
    "dict_future = {}\n",
    "df_mean_future = pd.DataFrame(index=pd.date_range(start=cutoff_date, periods=T, freq=\"W\"))\n",
    "for ind, col in enumerate(df.columns):\n",
    "    # Calculating the Weekly Returns\n",
    "    weekly_rets = np.exp(drift.values[ind] + 2*std.values[ind] * norm.ppf(np.random.rand(T, num_ports)))\n",
    "\n",
    "    # Getting the most current weekly return (run it back if it's too small)\n",
    "    n = -1\n",
    "    S0 = 0\n",
    "    while (S0 < 0.01) and (S0 > -0.01):\n",
    "        S0 = df.cumsum().iloc[n,ind]\n",
    "        n = n - 1\n",
    "    # Creating the empty list and filling the first row\n",
    "    price_list = np.zeros_like(weekly_rets)\n",
    "    price_list[0] = S0\n",
    "\n",
    "    # Performing Monte Carlo Situlation a 'num_ports' times\n",
    "    for t in range(1,T):\n",
    "        price_list[t] = price_list[t-1] * weekly_rets[t]\n",
    "        dict_future[col] = pd.DataFrame(price_list,index=date_range)\n",
    "        mean_future = pd.DataFrame(dict_future[col].mean(axis=1))\n",
    "        df_mean_future[col] = mean_future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_future.index = pd.to_datetime(df_mean_future.index)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df_new = pd.concat([df,df_mean_future.pct_change()], axis=1, join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10-Year Treasury Yield</th>\n",
       "      <th>10-Year Treasury Yield</th>\n",
       "      <th>10-Year Treasury Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-02-01</th>\n",
       "      <td>0.017115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-08</th>\n",
       "      <td>-0.009615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-15</th>\n",
       "      <td>-0.016990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-22</th>\n",
       "      <td>0.012346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-29</th>\n",
       "      <td>-0.026829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.001823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012904</td>\n",
       "      <td>-0.012904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005071</td>\n",
       "      <td>-0.005071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003196</td>\n",
       "      <td>-0.003196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009777</td>\n",
       "      <td>-0.009777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1118 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            10-Year Treasury Yield  10-Year Treasury Yield  \\\n",
       "2004-02-01                0.017115                     NaN   \n",
       "2004-02-08               -0.009615                     NaN   \n",
       "2004-02-15               -0.016990                     NaN   \n",
       "2004-02-22                0.012346                     NaN   \n",
       "2004-02-29               -0.026829                     NaN   \n",
       "...                            ...                     ...   \n",
       "2025-06-01                     NaN               -0.001823   \n",
       "2025-06-08                     NaN               -0.012904   \n",
       "2025-06-15                     NaN               -0.005071   \n",
       "2025-06-22                     NaN               -0.003196   \n",
       "2025-06-29                     NaN               -0.009777   \n",
       "\n",
       "            10-Year Treasury Yield  \n",
       "2004-02-01                     NaN  \n",
       "2004-02-08                     NaN  \n",
       "2004-02-15                     NaN  \n",
       "2004-02-22                     NaN  \n",
       "2004-02-29                     NaN  \n",
       "...                            ...  \n",
       "2025-06-01               -0.001823  \n",
       "2025-06-08               -0.012904  \n",
       "2025-06-15               -0.005071  \n",
       "2025-06-22               -0.003196  \n",
       "2025-06-29               -0.009777  \n",
       "\n",
       "[1118 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[\"10-Year Treasury Yield\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10-Year Treasury Yield</th>\n",
       "      <th>2-Year Treasury Yield</th>\n",
       "      <th>3-Month Treasury Yield</th>\n",
       "      <th>5-Year Treasury Yield</th>\n",
       "      <th>20-Year Treasury Yield</th>\n",
       "      <th>30-Year Treasury Yield</th>\n",
       "      <th>15-Year Mortgage Rate</th>\n",
       "      <th>30-Year Mortgage Rate</th>\n",
       "      <th>US Dollar Index</th>\n",
       "      <th>Industrial Production</th>\n",
       "      <th>...</th>\n",
       "      <th>10yTrea30yFRM (t-15)</th>\n",
       "      <th>10yTrea30yFRM (t-16)</th>\n",
       "      <th>10yTrea30yFRM (t-17)</th>\n",
       "      <th>10yTrea30yFRM (t-19)</th>\n",
       "      <th>10yTrea30yFRM (t-20)</th>\n",
       "      <th>10yTrea30yFRM (t-21)</th>\n",
       "      <th>10yTrea30yFRM (t-22)</th>\n",
       "      <th>10yTrea30yFRM (t-23)</th>\n",
       "      <th>10yTrea30yFRM (t-24)</th>\n",
       "      <th>SP500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-07-09 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-16 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>-0.004469</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>0.003534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-23 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>-0.002542</td>\n",
       "      <td>-0.002981</td>\n",
       "      <td>-0.009435</td>\n",
       "      <td>-0.006425</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>-0.008611</td>\n",
       "      <td>-0.006888</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.008106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-30 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>-0.001906</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>-0.003763</td>\n",
       "      <td>0.007241</td>\n",
       "      <td>0.017117</td>\n",
       "      <td>-0.008964</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.007580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-06 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000584</td>\n",
       "      <td>-0.004897</td>\n",
       "      <td>-0.003692</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-04</th>\n",
       "      <td>-0.028947</td>\n",
       "      <td>-0.008811</td>\n",
       "      <td>0.029963</td>\n",
       "      <td>-0.020408</td>\n",
       "      <td>-0.024213</td>\n",
       "      <td>-0.020202</td>\n",
       "      <td>0.035176</td>\n",
       "      <td>0.033486</td>\n",
       "      <td>-0.004766</td>\n",
       "      <td>-0.00542</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-11</th>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-0.023636</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>-0.017799</td>\n",
       "      <td>-0.011782</td>\n",
       "      <td>-0.004206</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-18</th>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.023965</td>\n",
       "      <td>-0.005587</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007712</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>-0.002981</td>\n",
       "      <td>-0.007769</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-25</th>\n",
       "      <td>-0.007958</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009877</td>\n",
       "      <td>-0.010363</td>\n",
       "      <td>-0.011475</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-02</th>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.033970</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.012469</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1118 rows Ã 1032 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     10-Year Treasury Yield  2-Year Treasury Yield  \\\n",
       "2023-07-09 00:00:00                     NaN                    NaN   \n",
       "2023-07-16 00:00:00                     NaN                    NaN   \n",
       "2023-07-23 00:00:00                     NaN                    NaN   \n",
       "2023-07-30 00:00:00                     NaN                    NaN   \n",
       "2023-08-06 00:00:00                     NaN                    NaN   \n",
       "...                                     ...                    ...   \n",
       "2023-06-04                        -0.028947              -0.008811   \n",
       "2023-06-11                         0.016260               0.020000   \n",
       "2023-06-18                         0.005333               0.023965   \n",
       "2023-06-25                        -0.007958               0.002128   \n",
       "2023-07-02                         0.018717               0.033970   \n",
       "\n",
       "                     3-Month Treasury Yield  5-Year Treasury Yield  \\\n",
       "2023-07-09 00:00:00                     NaN                    NaN   \n",
       "2023-07-16 00:00:00                     NaN                    NaN   \n",
       "2023-07-23 00:00:00                     NaN                    NaN   \n",
       "2023-07-30 00:00:00                     NaN                    NaN   \n",
       "2023-08-06 00:00:00                     NaN                    NaN   \n",
       "...                                     ...                    ...   \n",
       "2023-06-04                         0.029963              -0.020408   \n",
       "2023-06-11                        -0.023636               0.020833   \n",
       "2023-06-18                        -0.005587               0.017857   \n",
       "2023-06-25                         0.013109               0.000000   \n",
       "2023-07-02                         0.003697               0.035088   \n",
       "\n",
       "                     20-Year Treasury Yield  30-Year Treasury Yield  \\\n",
       "2023-07-09 00:00:00                     NaN                     NaN   \n",
       "2023-07-16 00:00:00                     NaN                     NaN   \n",
       "2023-07-23 00:00:00                     NaN                     NaN   \n",
       "2023-07-30 00:00:00                     NaN                     NaN   \n",
       "2023-08-06 00:00:00                     NaN                     NaN   \n",
       "...                                     ...                     ...   \n",
       "2023-06-04                        -0.024213               -0.020202   \n",
       "2023-06-11                         0.004963                0.002577   \n",
       "2023-06-18                         0.000000               -0.007712   \n",
       "2023-06-25                        -0.009877               -0.010363   \n",
       "2023-07-02                         0.012469                0.007853   \n",
       "\n",
       "                     15-Year Mortgage Rate  30-Year Mortgage Rate  \\\n",
       "2023-07-09 00:00:00                    NaN                    NaN   \n",
       "2023-07-16 00:00:00                    NaN                    NaN   \n",
       "2023-07-23 00:00:00                    NaN                    NaN   \n",
       "2023-07-30 00:00:00                    NaN                    NaN   \n",
       "2023-08-06 00:00:00                    NaN                    NaN   \n",
       "...                                    ...                    ...   \n",
       "2023-06-04                        0.035176               0.033486   \n",
       "2023-06-11                       -0.017799              -0.011782   \n",
       "2023-06-18                        0.004942              -0.002981   \n",
       "2023-06-25                       -0.011475              -0.002990   \n",
       "2023-07-02                        0.004975               0.005997   \n",
       "\n",
       "                     US Dollar Index  Industrial Production  ...  \\\n",
       "2023-07-09 00:00:00              NaN                    NaN  ...   \n",
       "2023-07-16 00:00:00              NaN                    NaN  ...   \n",
       "2023-07-23 00:00:00              NaN                    NaN  ...   \n",
       "2023-07-30 00:00:00              NaN                    NaN  ...   \n",
       "2023-08-06 00:00:00              NaN                    NaN  ...   \n",
       "...                              ...                    ...  ...   \n",
       "2023-06-04                 -0.004766               -0.00542  ...   \n",
       "2023-06-11                 -0.004206                0.00000  ...   \n",
       "2023-06-18                 -0.007769                0.00000  ...   \n",
       "2023-06-25                  0.006295                0.00000  ...   \n",
       "2023-07-02                  0.002355                0.00000  ...   \n",
       "\n",
       "                     10yTrea30yFRM (t-15)  10yTrea30yFRM (t-16)  \\\n",
       "2023-07-09 00:00:00                   NaN                   NaN   \n",
       "2023-07-16 00:00:00              0.001488              0.013378   \n",
       "2023-07-23 00:00:00              0.001539             -0.002542   \n",
       "2023-07-30 00:00:00              0.005195             -0.001906   \n",
       "2023-08-06 00:00:00             -0.000584             -0.004897   \n",
       "...                                   ...                   ...   \n",
       "2023-06-04                            NaN                   NaN   \n",
       "2023-06-11                            NaN                   NaN   \n",
       "2023-06-18                            NaN                   NaN   \n",
       "2023-06-25                            NaN                   NaN   \n",
       "2023-07-02                            NaN                   NaN   \n",
       "\n",
       "                     10yTrea30yFRM (t-17)  10yTrea30yFRM (t-19)  \\\n",
       "2023-07-09 00:00:00                   NaN                   NaN   \n",
       "2023-07-16 00:00:00              0.007406             -0.004469   \n",
       "2023-07-23 00:00:00             -0.002981             -0.009435   \n",
       "2023-07-30 00:00:00              0.000420              0.015289   \n",
       "2023-08-06 00:00:00             -0.003692              0.000878   \n",
       "...                                   ...                   ...   \n",
       "2023-06-04                            NaN                   NaN   \n",
       "2023-06-11                            NaN                   NaN   \n",
       "2023-06-18                            NaN                   NaN   \n",
       "2023-06-25                            NaN                   NaN   \n",
       "2023-07-02                            NaN                   NaN   \n",
       "\n",
       "                     10yTrea30yFRM (t-20)  10yTrea30yFRM (t-21)  \\\n",
       "2023-07-09 00:00:00                   NaN                   NaN   \n",
       "2023-07-16 00:00:00              0.021049              0.006923   \n",
       "2023-07-23 00:00:00             -0.006425              0.002118   \n",
       "2023-07-30 00:00:00             -0.003763              0.007241   \n",
       "2023-08-06 00:00:00              0.008801              0.001590   \n",
       "...                                   ...                   ...   \n",
       "2023-06-04                            NaN                   NaN   \n",
       "2023-06-11                            NaN                   NaN   \n",
       "2023-06-18                            NaN                   NaN   \n",
       "2023-06-25                            NaN                   NaN   \n",
       "2023-07-02                            NaN                   NaN   \n",
       "\n",
       "                     10yTrea30yFRM (t-22)  10yTrea30yFRM (t-23)  \\\n",
       "2023-07-09 00:00:00                   NaN                   NaN   \n",
       "2023-07-16 00:00:00              0.007136             -0.000342   \n",
       "2023-07-23 00:00:00             -0.008611             -0.006888   \n",
       "2023-07-30 00:00:00              0.017117             -0.008964   \n",
       "2023-08-06 00:00:00              0.002059              0.006657   \n",
       "...                                   ...                   ...   \n",
       "2023-06-04                            NaN                   NaN   \n",
       "2023-06-11                            NaN                   NaN   \n",
       "2023-06-18                            NaN                   NaN   \n",
       "2023-06-25                            NaN                   NaN   \n",
       "2023-07-02                            NaN                   NaN   \n",
       "\n",
       "                     10yTrea30yFRM (t-24)     SP500  \n",
       "2023-07-09 00:00:00                   NaN       NaN  \n",
       "2023-07-16 00:00:00              0.009989  0.003534  \n",
       "2023-07-23 00:00:00              0.005571  0.008106  \n",
       "2023-07-30 00:00:00              0.000190  0.007580  \n",
       "2023-08-06 00:00:00             -0.002167  0.002323  \n",
       "...                                   ...       ...  \n",
       "2023-06-04                            NaN       NaN  \n",
       "2023-06-11                            NaN       NaN  \n",
       "2023-06-18                            NaN       NaN  \n",
       "2023-06-25                            NaN       NaN  \n",
       "2023-07-02                            NaN       NaN  \n",
       "\n",
       "[1118 rows x 1032 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new1 = pd.concat([df,df_mean_future.pct_change()], axis=1)\n",
    "df_new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9796\\3282441081.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mecon_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_test_split_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mecon_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbaseline_ml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"> Performing Machine Learning\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m### Define the grids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\Documents\\GitHub\\Economic_Market_Forecasting\\Economic_Market_Forecasting\\EMF_webapp\\src\\notebooks\\utils\\objects.py\u001b[0m in \u001b[0;36mbaseline_ml\u001b[1;34m(self, target, X_train, X_test, y_train, y_test, baseline_models)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;31m# For model prediction data saving\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m         \u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbaseline_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_extract_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mis_empty_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m                 \u001b[1;31m# gh-17261\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                 warnings.warn(\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36mis_empty_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[0mis_none\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[0mis_list_like_without_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     \u001b[0mis_simple_empty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_list_like_without_dtype\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mis_none\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_simple_empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1536\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1537\u001b[0m         raise ValueError(\n\u001b[1;32m-> 1538\u001b[1;33m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1539\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "## Performing Machine Learning\n",
    "### Pick the best model\n",
    "\n",
    "test_size = T/len(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = econ_ml.train_test_split_data(data=df, target_col=target, test_size=0.15)\n",
    "model_results, baseline_preds, best_model, best_model_name = econ_ml.baseline_ml(target, X_train, X_test, y_train, y_test, baseline_models)\n",
    "print(\"> Performing Machine Learning\")\n",
    "### Define the grids\n",
    "params_RandomForest = {\n",
    "    \"n_estimators\": [120],\n",
    "    \"max_depth\": [10,15,17],\n",
    "    \"max_features\": [\"sqrt\", 3, 4]                          \n",
    "    }\n",
    "\n",
    "params_GradientBoosting = {\n",
    "    'n_estimators': [50, 100, 150],  \n",
    "    'learning_rate': [0.01, 0.05, 0.1],  \n",
    "    'max_depth': [3, 5, 7],  \n",
    "    }\n",
    "\n",
    "params_XGBRegressor = {\n",
    "    'n_estimators': [100, 150, 250],  \n",
    "    'learning_rate': [0.01, 0.05, 0.1],  \n",
    "    'max_depth': [ 5, 7, 11],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'max_leaf_nodes': [32, 64, 108]\n",
    "    }\n",
    "\n",
    "params_KNeighborsRegressor = {\n",
    "    'n_neighbors': [3, 5, 7, 9],  \n",
    "    'weights': ['uniform', 'distance'],  \n",
    "    'p': [1, 2],  \n",
    "    }\n",
    "\n",
    "params_SVR = {\n",
    "    'C': [0.1, 1.0, 10.0],  \n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  \n",
    "    'degree': [2, 3, 4],  \n",
    "    'gamma': ['scale', 'auto', 0.1, 1.0],  \n",
    "    }\n",
    "\n",
    "baseline_params = {\n",
    "    \"RandomForest\":params_RandomForest,\n",
    "    \"GradientBoosting\":params_GradientBoosting,\n",
    "    \"SVR\":params_SVR,\n",
    "    \"KNeighborsRegressor\":params_KNeighborsRegressor,\n",
    "    \"XGBRegressor\":params_XGBRegressor\n",
    "}\n",
    "print(\">>> Performing Grid Search\")\n",
    "def model_gridSearch(baseline_models,baseline_params,model_results,X_train,y_train,X_test,y_test,cross_val=5):\n",
    "    y_test = y_test.copy()\n",
    "    models_gridsearch = {}\n",
    "    for name, model in baseline_models.items():\n",
    "        if name in model_results.index.values:\n",
    "            for mod,params in baseline_params.items():\n",
    "                if name == mod:\n",
    "                    models_gridsearch[mod] = GridSearchCV(model, params, cv=cross_val, scoring=\"neg_root_mean_squared_error\", verbose=1, n_jobs=1)\n",
    "                    models_gridsearch[mod].fit(X_train, y_train)\n",
    "    best_grids = [(i, j.best_score_) for i, j in models_gridsearch.items()]\n",
    "    best_grids = pd.DataFrame(best_grids, columns=[\"Grid\", \"Best score\"]).sort_values(by=\"Best score\", ascending=False)\n",
    "    y_pred = models_gridsearch[best_grids.loc[0,\"Grid\"]].predict(X_test)\n",
    "    y_pred = pd.DataFrame(y_pred, columns=[target+\"_Prediction\"],index=y_test.index)\n",
    "    y_pred.index, y_test.index = pd.to_datetime(y_test.index), pd.to_datetime(y_test.index)\n",
    "    model_pred = pd.concat([y_test, y_pred], axis=1)\n",
    "    top_model = models_gridsearch[best_grids.loc[0,\"Grid\"]]\n",
    "    return models_gridsearch, best_grids, y_pred, y_test, model_pred, top_model\n",
    "models_gridsearch, best_grids, y_pred, y_test, model_pred, top_model = model_gridSearch(baseline_models,baseline_params,model_results,X_train,y_train,X_test,y_test,cross_val=cross_val)\n",
    "try:\n",
    "    X_test.index = pd.to_datetime(X_test.index)\n",
    "except:\n",
    "    pass\n",
    "full_test = pd.concat([model_pred, X_test], axis=1)\n",
    "print(\">>> Saving the best model and the data\")\n",
    "# Save the best model\n",
    "dump(top_model, r'C:\\Users\\Joan Oliver\\Documents\\GitHub\\Economic_Market_Forecasting\\Economic_Market_Forecasting\\EMF_webapp\\EMF_project\\models'+f\"\\{target}_best_model.joblib\")\n",
    "# Save the data\n",
    "model_pred.to_csv(data_path+f\"\\{target}_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
