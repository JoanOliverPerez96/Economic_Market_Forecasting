{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yfin\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "import re\n",
    "from path import Path\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from IPython.display import display, HTML\n",
    "from scipy.stats import pearsonr\n",
    "import itertools\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.tsa.stattools as tsa\n",
    "import pickle\n",
    "import joblib\n",
    "from joblib import dump\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "# FRED library\n",
    "from fredapi import Fred\n",
    "# API Key\n",
    "fred_key = '2e3cf97d1b456831253eda002ce25948'\n",
    "\n",
    "## Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "# Regression Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "# Deep Learning Models\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Conv1D, Dense, Flatten, Dropout\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from kerasbeats import prep_time_series, NBeatsModel\n",
    "from keras.losses import MeanSquaredLogarithmicError\n",
    "from keras.optimizers import Adam\n",
    "from keras import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metrics and processing\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from definitions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Date varialbes\n",
    "years = 20\n",
    "period=\"W\"\n",
    "cutoff_date=datetime.today().strftime('%Y-%m-%d')\n",
    "Ymd_str = datetime.today().strftime('%Y%m%d')\n",
    "Ym_str = datetime.today().strftime('%Y%m')\n",
    "Y_str = datetime.today().strftime('%Y')\n",
    "timeframe = 365*years\n",
    "today = datetime.today()\n",
    "end = today.strftime(\"%Y-%m-%d\")\n",
    "start = (today - dt.timedelta(days=timeframe)).strftime(\"%Y-%m-%d\")\n",
    "periods = period\n",
    "\n",
    "## Config varialbes\n",
    "ROOT_PATH = Path(ROOT_PATH)\n",
    "config_paths = [\n",
    "    \"config\\Market_Data_Config.csv\",\n",
    "    \"config\\Economic_Data_Config.csv\",\n",
    "    \"config\\Calc_Data_Config.csv\"]\n",
    "market_config = ROOT_PATH.joinpath(config_paths[0])\n",
    "economic_config = ROOT_PATH.joinpath(config_paths[1]).abspath()\n",
    "calc_config = ROOT_PATH.joinpath(config_paths[2]).abspath()\n",
    "target_list = pd.read_csv(market_config, sep=\";\", header=0).loc[:, \"Codigo\"].to_list()\n",
    "markets_used = pd.read_csv(market_config, sep=\";\", header=0).loc[:, \"Codigo\"].to_list()\n",
    "markets_remove = pd.read_csv(market_config, sep=\";\", header=0).loc[:, \"Market\"].to_list()\n",
    "# markets_used = ['SPY', 'GDX', 'BND']\n",
    "target = \"Financials\"\n",
    "seed = 2  # ML random seed\n",
    "extract = True\n",
    "cross_val=5\n",
    "medidas = [\"mean\", \"median\", \"mode\", \"Min\", \"Percentil_25\", \"Percentil_75\",\"Max\", \"var\", \"std\", \"skew\", \"kurt\"]\n",
    "extract = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the necessary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No folder created: data/result/processed_data\n",
      "No folder created: data/result/prediction_data\n",
      "No folder created: model\n",
      "No folder created: data/result/raw_data\n"
     ]
    }
   ],
   "source": [
    "## Paths variables\n",
    "PARENT_DIR = ROOT_PATH\n",
    "DATA_FOLDER = \"data/result/processed_data\"\n",
    "PREDICT_FOLDER = \"data/result/prediction_data\"\n",
    "RAW_FOLDER = \"data/result/raw_data\"\n",
    "MODEL_FOLDER = \"model\"\n",
    "\n",
    "data_path = PARENT_DIR+\"/\"+ DATA_FOLDER+\"/\"+ Y_str+\"/\"+ Ym_str+\"/\"+ Ymd_str\n",
    "predict_path = PARENT_DIR+\"/\"+ PREDICT_FOLDER+\"/\"+ Y_str+\"/\"+ Ym_str+\"/\"+ Ymd_str\n",
    "model_path = PARENT_DIR+\"/\"+ MODEL_FOLDER+\"/\"+ Y_str+\"/\"+ Ym_str+\"/\"+ Ymd_str\n",
    "raw_path = PARENT_DIR+\"/\"+ RAW_FOLDER+\"/\"+ Y_str+\"/\"+ Ym_str+\"/\"+ Ymd_str\n",
    "try:\n",
    "    os.makedirs(data_path)\n",
    "except:\n",
    "    print(\"No folder created: \"+DATA_FOLDER)\n",
    "try:\n",
    "    os.makedirs(predict_path)\n",
    "except:\n",
    "    print(\"No folder created: \"+PREDICT_FOLDER)\n",
    "try:\n",
    "    os.makedirs(model_path)\n",
    "except:\n",
    "    print(\"No folder created: \"+MODEL_FOLDER)\n",
    "try:\n",
    "    os.makedirs(raw_path)\n",
    "except:\n",
    "    print(\"No folder created: \"+RAW_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dictionary(config, markets_used):\n",
    "        config = config.dropna()\n",
    "        if markets_used is None:\n",
    "            pass\n",
    "        else:\n",
    "            markets_used = markets_used\n",
    "            config = config[config[\"Codigo\"].isin(markets_used)]\n",
    "        config.set_index('Codigo', inplace=True)\n",
    "        if config is None:\n",
    "            raise ValueError(\"No config loaded.\")\n",
    "        if config.columns.size >2:\n",
    "            config = config.iloc[:, :2]\n",
    "        return config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = pd.read_csv(market_config, sep=';', decimal=',', header=0)\n",
    "market_dict = convert_to_dictionary(market, markets_used=markets_used)\n",
    "market_dict = market_dict['Market']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "economic = pd.read_csv(economic_config, sep=';', decimal=',', header=0)\n",
    "economic_dict = convert_to_dictionary(economic, markets_used=None)\n",
    "economic_dict = economic_dict['Indicador']\n",
    "\n",
    "indicators = {}\n",
    "for ind in list(economic[\"Tipo\"].unique()):\n",
    "    indicators[ind] = economic[economic[\"Tipo\"] == ind][\"Indicador\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Indicator Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -->Extracting 10-Year Treasury Yield...\n",
      "   -->Extracting 2-Year Treasury Yield...\n",
      "   -->Extracting Federal Funds Effective Rate...\n",
      "   -->Extracting 1-Month Treasury Yield...\n",
      "   -->Extracting 3-Month Treasury Yield...\n",
      "   -->Extracting 5-Year Treasury Yield...\n",
      "   -->Extracting 20-Year Treasury Yield...\n",
      "   -->Extracting 30-Year Treasury Yield...\n",
      "   -->Extracting 15-Year Mortgage Rate...\n",
      "   -->Extracting 30-Year Mortgage Rate...\n",
      "   -->Extracting 10-Year Euro Gov Bond Yield...\n",
      "   -->Extracting 3-Month Euro Gov Bond Yield...\n",
      "   -->Extracting 3-Month China Gov Bond Yield...\n",
      "   -->Extracting 10-Year India Gov Bond Yield...\n",
      "   -->Extracting CPI...\n",
      "   -->Extracting PPI...\n",
      "   -->Extracting China CPI...\n",
      "   -->Extracting Europe CPI...\n",
      "   -->Extracting Unemployment Rate...\n",
      "   -->Extracting GDP...\n",
      "   -->Extracting Real GDP...\n",
      "   -->Extracting Consumer Confidence Index...\n",
      "   -->Extracting Government Debt...\n",
      "   -->Extracting Debt Service vs Disposable Income...\n",
      "   -->Extracting Credit Card Delinquency...\n",
      "   -->Extracting US Dollar Index...\n",
      "   -->Extracting Corporate Profits...\n",
      "   -->Extracting EBIT...\n",
      "   -->Extracting Retained Earnings...\n",
      "   -->Extracting VIX...\n",
      "   -->Extracting Building Permits...\n",
      "   -->Extracting Residential Property Prices...\n",
      "   -->Extracting Housing Starts...\n",
      "   -->Extracting Velocity of Money...\n",
      "   -->Extracting Retail Sales...\n",
      "   -->Extracting Industrial Production...\n"
     ]
    }
   ],
   "source": [
    "fred = Fred(api_key=fred_key)\n",
    "\n",
    "indicators_df = pd.DataFrame() # DataFrame para almacenar los datos extraidos\n",
    "# Acceder al diccionario de indicadores economicos para extraer sus datos (utilizando el objeto 'fred' y la funcion 'get_series') y almacenarlos en un DataFrame\n",
    "for code,indicator in economic_dict.items():\n",
    "    print(f'   -->Extracting {indicator}...')\n",
    "    indicators_df[indicator] = fred.get_series(code)\n",
    "path = ROOT_PATH.joinpath('data', 'result', 'raw_data', 'indicators_df.csv')\n",
    "indicators_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Indicator Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_method=\"ffill\"\n",
    "indicator_dict = indicators\n",
    "df_indicators = indicators_df.loc[start:end]\n",
    "df_indicators.index = pd.to_datetime(df_indicators.index, utc=True, format='%Y-%m-%d')\n",
    "df_indicators = df_indicators.resample(periods).last()\n",
    "# Rellenar los datos vacios con el dato anterior\n",
    "df_indicators_limpio = df_indicators.fillna(method=fill_method)\n",
    "if fill_method == 'ffill':\n",
    "    # Rellenar los siguientes datos vacios con el ultimo dato\n",
    "    df_indicators_limpio.fillna(method='bfill', inplace=True) \n",
    "# Guardar las tablas de indicadores en csv\n",
    "for ind_name, ind_list in indicator_dict.items():\n",
    "    path = ROOT_PATH.joinpath('data', 'result',  'processed_data', 'indicators', ind_name+'.csv')\n",
    "    df_indicators[ind_list].dropna().to_csv(path)\n",
    "# Generar el diferencial de los datos\n",
    "df_indicators_diff = df_indicators_limpio.diff().fillna(0)\n",
    "# Generar el dataframe de rendimiento de los datos\n",
    "df_indicators_rets = df_indicators_limpio.pct_change().fillna(0)\n",
    "dfs = [df_indicators, df_indicators_limpio, df_indicators_diff, df_indicators_rets]\n",
    "for df in dfs:\n",
    "    try:\n",
    "        df.index = df.index.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        print(\"Error in date formatting\")\n",
    "df_indicators_cum = df_indicators_rets.cumsum().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  17 of 17 completed\n"
     ]
    }
   ],
   "source": [
    "stocks = list(market_dict.keys())\n",
    "yfin.pdr_override()\n",
    "# Extraer los precios de !Yahoo Finanzas para cada uno de los indices y almacenarlos en el DataFrame 'markets'\n",
    "markets = pdr.get_data_yahoo(stocks,start=start,end=end)\n",
    "# Filtrar el DataFrame quedandonos con la columna de 'Adj Close' y el rango temporal previamente definido\n",
    "market_hist = markets[\"Adj Close\"].loc[start:end]# Guardar el DataFrame como un archivo csv\n",
    "path = ROOT_PATH.joinpath('data', 'result', 'raw_data', 'market_df.csv')\n",
    "market_hist.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Indicator Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample=periods\n",
    "fill_method=\"ffill\"\n",
    "df_markets = market_hist.rename(columns=market_dict)\n",
    "# Filtrar los datos de mercado de los primeros 23 aÃ±os\n",
    "df_markets = df_markets.loc[start:end]\n",
    "df_markets.index = pd.to_datetime(df_markets.index, utc=True, format='%Y-%m-%d')\n",
    "# df_markets.index = df_markets.index.strftime('%Y-%m-%d')\n",
    "\n",
    "# Hacer el resampleo de datos\n",
    "df_markets = df_markets.resample(resample).fillna(method=fill_method)\n",
    "if fill_method == 'ffill':\n",
    "    # Rellenar los siguientes datos vacios con el ultimo dato\n",
    "    df_markets.fillna(method='bfill', inplace=True) \n",
    "\n",
    "# Crear DataFrame de rendimiento diario de mercados\n",
    "df_market_rets = df_markets.pct_change().fillna(0)\n",
    "df_market_rets.index = pd.to_datetime(df_market_rets.index, utc=True, format='%Y-%m-%d')\n",
    "df_market_rets.index = df_market_rets.index.strftime('%Y-%m-%d')\n",
    "# Crear DataFrame de rendimiento acumulado de mercados\n",
    "df_market_cum = df_market_rets.cumsum().fillna(0)\n",
    "\n",
    "# Crear DataFrame de diferencial de mercados\n",
    "df_market_diff = df_markets.diff().fillna(0)\n",
    "\n",
    "# Guardar tablas procesadas de mercados\n",
    "\n",
    "path = ROOT_PATH.joinpath('data', 'result', 'processed_data', 'markets')\n",
    "df_markets.to_csv(path.joinpath('market_hist.csv'))\n",
    "df_market_rets.to_csv(path.joinpath('market_rets.csv'))\n",
    "df_market_cum.to_csv(path.joinpath('market_cum.csv'))\n",
    "df_market_diff.to_csv(path.joinpath('market_diff.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge indicator and market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_market_dfs = [df_markets,df_market_rets,df_market_cum,df_market_diff]\n",
    "list_indicators_dfs = [df_indicators_limpio,df_indicators_rets,df_indicators_cum,df_indicators_diff]\n",
    "\n",
    "list_all_dfs = []\n",
    "for df_indicators, df_markets in zip(list_indicators_dfs, list_market_dfs):\n",
    "    if type(df_indicators.index[0]) != str:\n",
    "        try:\n",
    "            df_indicators.index = df_indicators.index.strftime(\"%Y-%m-%d\")\n",
    "        except:\n",
    "            print(\"Don't change date format\")\n",
    "    if type(df_markets.index[0]) != str:\n",
    "        try:\n",
    "            df_markets.index = df_markets.index.strftime(\"%Y-%m-%d\").str.split(\" \").str[0]\n",
    "        except:\n",
    "            print(\"Don't change date format\")\n",
    "    df = pd.merge(df_indicators,df_markets, left_index=True, right_index=True,how='outer').fillna(method='ffill')\n",
    "    list_all_dfs.append(df)\n",
    "path = ROOT_PATH.joinpath('data', 'result', 'processed_data', 'indicators', 'model_data.csv')\n",
    "list_all_dfs[1].to_csv(path)\n",
    "df_all_data, df_all_data_rets, df_all_data_cum, df_all_data_diff = list_all_dfs[0], list_all_dfs[1], list_all_dfs[2], list_all_dfs[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all_data_rets.copy()\n",
    "threshold_mad = 6\n",
    "\n",
    "median = np.median(df)\n",
    "mad = np.median(np.abs(df - median))\n",
    "threshold_mad = threshold_mad\n",
    "modified_z_scores = 0.6745 * (df - median) / mad\n",
    "outliers_mad = df[np.abs(modified_z_scores) > threshold_mad]\n",
    "df_no_outliers = df[np.abs(modified_z_scores) <= threshold_mad]\n",
    "\n",
    "for column in df_no_outliers.columns:\n",
    "    null_indexes = df_no_outliers[column].isnull()\n",
    "    null_indexes_shifted = null_indexes.shift(1, fill_value=False)\n",
    "    null_indexes_shifted_rev = null_indexes.shift(-1, fill_value=False)\n",
    "    mask = null_indexes | null_indexes_shifted | null_indexes_shifted_rev\n",
    "\n",
    "    while mask.any():  # Repeat until there are no more NaN values surrounded by non-NaN values\n",
    "        avg_values = df_no_outliers[column].rolling(3, min_periods=1, center=True).mean()  # Calculate rolling average of size 3\n",
    "        df_no_outliers[column] = np.where(mask, avg_values, df_no_outliers[column])  # Replace NaN values with rolling average values\n",
    "\n",
    "        null_indexes = df_no_outliers[column].isnull()\n",
    "        null_indexes_shifted = null_indexes.shift(1, fill_value=False)\n",
    "        null_indexes_shifted_rev = null_indexes.shift(-1, fill_value=False)\n",
    "        mask = null_indexes | null_indexes_shifted | null_indexes_shifted_rev\n",
    "df = df_no_outliers.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_data[\"CAPE Ratio\"] = df_all_data[\"SP500\"]/(df_all_data[\"Corporate Profits\"]*0.01)\n",
    "df[\"CAPE Ratio\"] = df_all_data[\"SP500\"]/(df_all_data[\"Corporate Profits\"]*0.01)\n",
    "\n",
    "# df_all_data[\"CAPE Ratio\"].plot()\n",
    "def trend_line(df, name, deg=2):\n",
    "    coef = np.polyfit(range(0,len(df[name])), df[name], deg)\n",
    "    x_trend = np.linspace(0,len(df[name]),len(df[name]))\n",
    "    y_trend = np.polyval(coef, x_trend)\n",
    "    df = pd.DataFrame(y_trend, index=df.index, columns=[name])\n",
    "    return df\n",
    "\n",
    "# df_all_data = pd.DataFrame()\n",
    "df_all_data[\"SP_GDP\"] = df_all_data[\"SP500\"]/(df_all_data[\"GDP\"]*.01)\n",
    "df_all_data[\"SP_GDP_trend\"] = trend_line(df_all_data, \"SP_GDP\", deg=5)\n",
    "df[\"SP_GDP\"] = df_all_data[\"SP500\"]/(df_all_data[\"GDP\"]*.01)\n",
    "df[\"SP_GDP_trend\"] = trend_line(df_all_data, \"SP_GDP\", deg=5)\n",
    "\n",
    "# df_all_data = pd.DataFrame()\n",
    "std = df_all_data[\"SP_GDP\"].std()\n",
    "df_all_data[\"SP_GDP_1std\"] = df_all_data[\"SP_GDP_trend\"] + (std)\n",
    "df[\"SP_GDP_1std\"] = df_all_data[\"SP_GDP_trend\"] + (std)\n",
    "\n",
    "# df_all_data = df_all_data.copy()\n",
    "# df_ts = df_all_data.loc[:,df_all_data.columns.str.contains(f\"t-\")]\n",
    "# df_all_data.drop(df_ts.columns,axis=1,inplace=True)\n",
    "for ma in df_all_data.columns:\n",
    "    df_all_data[f\"{ma}_MA\"] = df_all_data[[ma]].rolling(window=52).mean().fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    df_all_data[f\"{ma}_std\"] = df_all_data[[ma]].rolling(window=52).std().fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    df_all_data[f\"{ma}_trend\"] = trend_line(df_all_data[[ma]], ma, deg=6)\n",
    "    df_all_data[f\"{ma}_MA_trend_dif\"] = df_all_data[f\"{ma}_trend\"] - df_all_data[f\"{ma}_MA\"]\n",
    "    \n",
    "    df[f\"{ma}_MA\"] = df_all_data[[ma]].rolling(window=52).mean().fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    df[f\"{ma}_trend\"] = trend_line(df_all_data[[ma]], ma, deg=6)\n",
    "    df[f\"{ma}_MA_trend_dif\"] = df_all_data[f\"{ma}_trend\"] - df_all_data[f\"{ma}_MA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Indentifying the most important features\n",
    "##### Splitting the data\n",
    "\n",
    "##### Creating the baseline for feature importance\n",
    "baseline_models = {\n",
    "                # \"LinearRegression\": LinearRegression(), \n",
    "                # \"PolynomialFeatures\": PolynomialFeatures(),\n",
    "                # \"DecisionTree\": DecisionTreeRegressor(), \n",
    "                \"RandomForest\": RandomForestRegressor(),\n",
    "                \"GradientBoosting\": GradientBoostingRegressor(), \n",
    "                \"SVR\": SVR(), \n",
    "                \"KNeighborsRegressor\": KNeighborsRegressor(),\n",
    "                \"XGBRegressor\": XGBRegressor(),\n",
    "                }\n",
    "#### Splitting the data\n",
    "data = df.copy()\n",
    "test_size = 0.15\n",
    "X = data.drop([target], axis=1)\n",
    "y = data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "#### Creating the baseline\n",
    "model_results = pd.DataFrame()\n",
    "model_scores_dict = {}\n",
    "model_mse_dict = {}\n",
    "model_r2_dict = {}\n",
    "\n",
    "# For model prediction data saving\n",
    "preds = {}\n",
    "preds[target] = pd.Series(y_test)\n",
    "\n",
    "for name, model in baseline_models.items():\n",
    "    print(\"Processing \"+name)\n",
    "    if name == \"PolynomialFeatures\":\n",
    "        pass\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        # y_pred = pd.DataFrame(y_pred,index=y_test.index,columns=[name+\"_\"+target+\"_pred\"])\n",
    "        y_pred = pd.Series(y_pred,index=y_test.index)\n",
    "        preds[name+\"_\"+target+\"_pred\"] = y_pred\n",
    "        score = model.score(X_train, y_train)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        model_scores_dict[name] = score\n",
    "        model_mse_dict[name] = mse\n",
    "        model_r2_dict[name] = r2\n",
    "\n",
    "model_results = model_results.append([model_scores_dict,model_mse_dict,model_r2_dict], ignore_index=True).T.sort_values(by=0, ascending=False)\n",
    "model_results.columns = [\"score\",\"mse\",\"r2\"]\n",
    "model_results[\"rmse\"] = np.sqrt(model_results[\"mse\"])\n",
    "baseline_preds = pd.DataFrame(preds)\n",
    "\n",
    "# Pick the models that have a score above 0.75\n",
    "model_results = model_results[model_results.loc[:,\"score\"]>(max(model_results.loc[:,\"score\"])*.75)]\n",
    "# Sort by rmse\n",
    "model_results.sort_values(by=\"rmse\",ascending=True,inplace=True)\n",
    "# Pick the model with the best rmse\n",
    "best_model_name = model_results.index[0]\n",
    "best_model = baseline_models[best_model_name]\n",
    "#### Feature importance\n",
    "df_data = df.loc[:cutoff_date]\n",
    "model = best_model\n",
    "accepted_importance = 0.85\n",
    "\n",
    "X = df_data.drop([target], axis=1)\n",
    "y = df_data[target]\n",
    "\n",
    "feat_imp_model = model\n",
    "feat_imp_model.fit(X,y)\n",
    "score = feat_imp_model.score(X,y)\n",
    "\n",
    "feature_importance = feat_imp_model.feature_importances_\n",
    "\n",
    "df_feature_importance = pd.DataFrame(index=X.columns,data=feature_importance, columns=[\"Importance\"]).sort_values(by=\"Importance\", ascending=False)\n",
    "df_feature_importance[\"Cum_Importance\"] = df_feature_importance.cumsum()\n",
    "df_top_feature_importance = df_feature_importance[df_feature_importance[\"Cum_Importance\"] < accepted_importance]\n",
    "\n",
    "df_top_data = df_data.loc[:,df_data.columns.isin(df_top_feature_importance.index)]\n",
    "df_top_data = pd.concat([df_top_data, df_data[[target]]], axis=1).dropna()     \n",
    "\n",
    "#### Feature removal\n",
    "def feature_removal(df, df_top_data, model_results, best_model_name, score):\n",
    "    best_model_score = model_results.loc[best_model_name,\"score\"]\n",
    "    if score > best_model_score*.9:\n",
    "        print(\"We choose to remove \"+str(len(df.columns)-len(df_top_data.columns))+\" features\")\n",
    "        df = df_top_data.copy()\n",
    "    else:\n",
    "        print(\"We choose to keep the original df with \"+str(len(df_top_data.columns))+\" features\")\n",
    "    return df\n",
    "\n",
    "df = feature_removal(df, df_top_data, model_results, best_model_name, score)\n",
    "## Saving the processed data (ready for ML)\n",
    "df.to_csv(data_path+f\"/processed_data_{target}_{Ymd_str}.csv\", index=True, index_label=\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RandomForest\n",
      "Processing GradientBoosting\n",
      "Processing SVR\n",
      "Processing KNeighborsRegressor\n",
      "Processing XGBRegressor\n"
     ]
    }
   ],
   "source": [
    "baseline_models = {\n",
    "                # \"LinearRegression\": LinearRegression(), \n",
    "                # \"PolynomialFeatures\": PolynomialFeatures(),\n",
    "                # \"DecisionTree\": DecisionTreeRegressor(), \n",
    "                \"RandomForest\": RandomForestRegressor(),\n",
    "                \"GradientBoosting\": GradientBoostingRegressor(), \n",
    "                \"SVR\": SVR(), \n",
    "                \"KNeighborsRegressor\": KNeighborsRegressor(),\n",
    "                \"XGBRegressor\": XGBRegressor(),\n",
    "                }\n",
    "#### Splitting the data\n",
    "data = df.copy()\n",
    "test_size = 0.15\n",
    "X = data.drop([target], axis=1)\n",
    "y = data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "#### Creating the baseline\n",
    "model_results = pd.DataFrame()\n",
    "model_scores_dict = {}\n",
    "model_mse_dict = {}\n",
    "model_r2_dict = {}\n",
    "\n",
    "# For model prediction data saving\n",
    "preds = {}\n",
    "preds[target] = pd.Series(y_test)\n",
    "\n",
    "for name, model in baseline_models.items():\n",
    "    print(\"Processing \"+name)\n",
    "    if name == \"PolynomialFeatures\":\n",
    "        pass\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        # y_pred = pd.DataFrame(y_pred,index=y_test.index,columns=[name+\"_\"+target+\"_pred\"])\n",
    "        y_pred = pd.Series(y_pred,index=y_test.index)\n",
    "        preds[name+\"_\"+target+\"_pred\"] = y_pred\n",
    "        score = model.score(X_train, y_train)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        model_scores_dict[name] = score\n",
    "        model_mse_dict[name] = mse\n",
    "        model_r2_dict[name] = r2\n",
    "\n",
    "model_results = model_results.append([model_scores_dict,model_mse_dict,model_r2_dict], ignore_index=True).T.sort_values(by=0, ascending=False)\n",
    "model_results.columns = [\"score\",\"mse\",\"r2\"]\n",
    "model_results[\"rmse\"] = np.sqrt(model_results[\"mse\"])\n",
    "baseline_preds = pd.DataFrame(preds)\n",
    "\n",
    "# Pick the models that have a score above 0.75\n",
    "model_results = model_results[model_results.loc[:,\"score\"]>(max(model_results.loc[:,\"score\"])*.75)]\n",
    "# Sort by rmse\n",
    "model_results.sort_values(by=\"rmse\",ascending=True,inplace=True)\n",
    "# Pick the model with the best rmse\n",
    "best_model_name = model_results.index[0]\n",
    "best_model = baseline_models[best_model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_RandomForest = {\n",
    "    \"n_estimators\": [120],\n",
    "    \"max_depth\": [10,15,17],\n",
    "    \"max_features\": [\"sqrt\", 3, 4]                          \n",
    "    }\n",
    "\n",
    "params_GradientBoosting = {\n",
    "    'n_estimators': [100, 150],  # 50, \n",
    "    'learning_rate': [0.01, 0.05, 0.1],  \n",
    "    'max_depth': [5, 7],  \n",
    "    }\n",
    "\n",
    "params_XGBRegressor = {\n",
    "    'n_estimators': [150, 250],  # 100\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  \n",
    "    'max_depth': [ 5, 7, 11],\n",
    "    # 'subsample': [0.8, 1.0],\n",
    "    # 'max_leaf_nodes': [32, 64, 108]\n",
    "    }\n",
    "\n",
    "params_KNeighborsRegressor = {\n",
    "    'n_neighbors': [3, 5, 7, 9],  \n",
    "    'weights': ['uniform', 'distance'],  \n",
    "    'p': [1, 2],  \n",
    "    }\n",
    "\n",
    "params_SVR = {\n",
    "    'C': [0.1, 1.0, 10.0],  \n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  \n",
    "    'degree': [2, 3, 4],  \n",
    "    'gamma': ['scale', 'auto', 0.1, 1.0],  \n",
    "    }\n",
    "\n",
    "baseline_params = {\n",
    "    \"RandomForest\":params_RandomForest,\n",
    "    \"GradientBoosting\":params_GradientBoosting,\n",
    "    \"SVR\":params_SVR,\n",
    "    \"KNeighborsRegressor\":params_KNeighborsRegressor,\n",
    "    \"XGBRegressor\":params_XGBRegressor\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_gridSearch(baseline_models,baseline_params,model_results,X_train,y_train,X_test,y_test,cross_val=5):\n",
    "    y_test = y_test.copy()\n",
    "    models_gridsearch = {}\n",
    "    for name, model in baseline_models.items():\n",
    "        if name in model_results.index.values:\n",
    "            for mod,params in baseline_params.items():\n",
    "                if name == mod:\n",
    "                    models_gridsearch[mod] = GridSearchCV(model, params, cv=cross_val, scoring=\"neg_root_mean_squared_error\", verbose=1, n_jobs=1)\n",
    "                    models_gridsearch[mod].fit(X_train, y_train)\n",
    "    best_grids = [(i, j.best_score_) for i, j in models_gridsearch.items()]\n",
    "    best_grids = pd.DataFrame(best_grids, columns=[\"Grid\", \"Best score\"]).sort_values(by=\"Best score\", ascending=False)\n",
    "    top_model = models_gridsearch[best_grids.loc[0,\"Grid\"]]\n",
    "    return models_gridsearch, best_grids, top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31672\\897640204.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodels_gridsearch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_grids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_gridSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseline_models\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbaseline_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_results\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcross_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31672\\2215244769.py\u001b[0m in \u001b[0;36mmodel_gridSearch\u001b[1;34m(baseline_models, baseline_params, model_results, X_train, y_train, X_test, y_test, cross_val)\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mmodels_gridsearch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcross_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"neg_root_mean_squared_error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                     \u001b[0mmodels_gridsearch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mbest_grids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels_gridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mbest_grids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_grids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Grid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Best score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Best score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    849\u001b[0m                     )\n\u001b[0;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[1;32m--> 851\u001b[1;33m                         \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m                     )\n\u001b[0;32m    853\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 289\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 289\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    465\u001b[0m                     \u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m                 )\n\u001b[1;32m--> 467\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m             )\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 289\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 289\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m             \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m         )\n\u001b[0;32m   1322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Joan Oliver\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models_gridsearch, best_grids, top_model = model_gridSearch(baseline_models,baseline_params,model_results,X_train,y_train,X_test,y_test,cross_val=cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(top_model, model_path+f\"\\{target}_best_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
